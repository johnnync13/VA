{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------\n",
    "----------------------------------------------------------------------------------------------------\n",
    "<h1><center>\n",
    "    \n",
    "Exam II Partial (version A)\n",
    " \n",
    "( 9th of January, 2020 )\n",
    "</center></h1>    \n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Please read the exercices carefully, write the necesary code and respond to all the questions. The code needs to be properly commented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1  (3 points)\n",
    "\n",
    "Given a query image `images/letterT.png`, apply the HOG descriptor in order to detect its location in the target image `images/hoddie.png`.\n",
    "\n",
    "<img src=\"images/HOG_detection.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) (1 Points)** Load the query image and obtain its HOG descriptor. Plot them in a 1x2 figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) (1 Points)** Perform a sliding windows over the target image and obtain the HOG descriptor for each region. Then compare with the HOG descriptor of the query image using an appropriate similarity measure.\n",
    "\n",
    "In order to accelerate algorithm execution, you can apply a sliding window with a step of 5 pixels both vertically and horizontally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) (1 Points)**  Visualise the location within the target image with highest similarity with the query image. Use a 1x3 plot to show the query image, HOG distance of the target image and the original image with the breast region match as shown at the beginning of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2  (3.5 points)\n",
    "\n",
    "Extract features from a set of images, build a simple classifier based on the concept of distance between feature vectors. The set of images consists of 200 training samples and 100 testing samples representing faces (positive samples) and non-faces (negative samples). The code to load the training and testing images is provided below. Complete all sections from `a)` to `c)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy\n",
    "import skimage\n",
    "from skimage import io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "\n",
    "pos_path_train = \"./images/trainingdata/faces/\"\n",
    "neg_path_train = \"./images/trainingdata/nonfaces/\"\n",
    "\n",
    "pos_path_test = \"./images/trainingdata/faces/test/\"\n",
    "neg_path_test = \"./images/trainingdata/nonfaces/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(path):\n",
    "    imgs_list = [io.imread(path+f) for f in os.listdir(path) if \".png\" in f]\n",
    "    \n",
    "    # Do not change this line! Images must be resized for the features calculation to taking less time.\n",
    "    #imgs_list = [resize(im, (50,50)) for im in imgs_list]\n",
    "    return imgs_list\n",
    "\n",
    "def plotImages(img1, img2):\n",
    "    fig, ax= plt.subplots(ncols=2, nrows=1, figsize=(20,30))\n",
    "\n",
    "    ax[0].imshow(img1)\n",
    "    ax[1].imshow(img2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training images\n",
    "pos_images_train = loadImages(pos_path_train)\n",
    "neg_images_train = loadImages(neg_path_train)\n",
    "# Load testing images\n",
    "pos_images_test = loadImages(pos_path_test)\n",
    "neg_images_test = loadImages(neg_path_test)\n",
    "\n",
    "plotImages(pos_images_train[0], neg_images_train[0])\n",
    "\n",
    "# Training set\n",
    "print(len(pos_images_train), len(neg_images_train))\n",
    "# Testing set\n",
    "print(len(pos_images_test), len(neg_images_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) (1 point)** Load the filter banks provided and extract features on the grayscale version of the `train` and `test` images.\n",
    "\n",
    "You should have a resulting matrix for the training set with a size of (200, 49), 200 images and 49 features per image. And a resulting matrix for the test set with a size of (100, 49), 100 images and 49 features per images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import filters\n",
    "import LM_filters\n",
    "filter_bank = LM_filters.makeLMfilters()\n",
    "\n",
    "# TRAINING set\n",
    "# Join all images in a list\n",
    "train_images = neg_images_train + pos_images_train\n",
    "# Obtain class labels\n",
    "train_labels = list(np.zeros(len(neg_images_train))) + list(np.ones(len(pos_images_train)))\n",
    "train_labels = [int(l) for l in train_labels]\n",
    "\n",
    "# TESTING set\n",
    "# Join all images in a list\n",
    "test_images = neg_images_test + pos_images_test\n",
    "# Obtain class labels\n",
    "test_labels = list(np.zeros(len(neg_images_test))) + list(np.ones(len(pos_images_test)))\n",
    "test_labels = [int(l) for l in test_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Solution'''\n",
    "\n",
    "def features_from_filter_bank(image, filter_bank, n_filters):\n",
    "    # COMPLETE\n",
    "\n",
    "    return features_for_im\n",
    "\n",
    "def getImageFeatures(all_images,  filter_bank):\n",
    "    # COMPLETE\n",
    "       \n",
    "    return all_feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_features = getImageFeatures(train_images, filter_bank)\n",
    "test_features = getImageFeatures(test_images, filter_bank)\n",
    "\n",
    "# It takes around 6 min to extract the features of both train and test samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) (1 point)** Once the features have been extracted, build a classifier based on the concept of distance between feature vectors (a nearest neightbor classifier). For this purpose, you should define the following functions:\n",
    "\n",
    "- `predictLabel(train_features, train_labels, sample_features)`: predict the label for the feature vector of a given sample given the training features and their corresponding labels. For this purpose, the distances between the sample feature vector and the training feature vectors are calculated. The function should return the label of the training sample with minimum distance\n",
    "\n",
    "**NOTE**: Assuming that $f(x) \\in \\mathbb{R}^D$ represents a set of features for $x$. Given a query image $x$ and another image $x^m$ from the database, we can compute the distance between images as:\n",
    "$$\n",
    "\\text{distance}\\left( f(x) , \\, f(x^m) \\right) = \\| \\text{feat}(x)  - \\text{feat}(x^m)  \\|_2 =  \\sqrt{ \\sum_{d=1}^\\text{D} \\left( f(x)_d - f(x^m)_d  \\right)^2 }\n",
    "$$\n",
    "\n",
    "\n",
    "- `predictNearestNeighbor(train_features, train_labels, features)`: predicts the labels for a given list of features vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Solution'''\n",
    "def predictLabel(train_features, train_labels, sample_features):\n",
    "    # COMPLETE\n",
    "    \n",
    "def predictNearestNeighbor(train_features, train_labels, features):\n",
    "    # COMPLETE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) (1.5 points)** Implement a function for calculating the prediction accuracy given a set of true labels and a set of predicted labels. Calculate the accuracy on the testing set with respect to the previously calculated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Solution'''\n",
    "def accuracy(true_labels, predicted_labels):\n",
    "    # COMPLETE\n",
    "\n",
    "    return acc\n",
    "\n",
    "# Obtain test_labels\n",
    "# COMPLETE\n",
    "\n",
    "# Print testing accuracy\n",
    "# COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3  (3.5 points)\n",
    "\n",
    "Extract features from a set of images, train an AdaBoost classifier and evaluate its performance. The set of images consists of 200 training samples and 100 testing samples representing faces (positive samples) and non-faces (negative samples).The code to load the training and testing images is provided below. Complete all sections from `a)` to `d)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy\n",
    "import skimage\n",
    "from skimage import io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "\n",
    "pos_path_train = \"./images/trainingdata/faces/\"\n",
    "neg_path_train = \"./images/trainingdata/nonfaces/\"\n",
    "\n",
    "pos_path_test = \"./images/trainingdata/faces/test/\"\n",
    "neg_path_test = \"./images/trainingdata/nonfaces/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(path):\n",
    "    imgs_list = [io.imread(path+f) for f in os.listdir(path) if \".png\" in f]\n",
    "    \n",
    "    # Do not change this line! Images must be resized for the features calculation to taking less time.\n",
    "    #imgs_list = [resize(im, (50,50)) for im in imgs_list]\n",
    "    return imgs_list\n",
    "\n",
    "def plotImages(img1, img2):\n",
    "    fig, ax= plt.subplots(ncols=2, nrows=1, figsize=(20,30))\n",
    "\n",
    "    ax[0].imshow(img1)\n",
    "    ax[1].imshow(img2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load training images\n",
    "pos_images_train = loadImages(pos_path_train)\n",
    "neg_images_train = loadImages(neg_path_train)\n",
    "# Load testing images\n",
    "pos_images_test = loadImages(pos_path_test)\n",
    "neg_images_test = loadImages(neg_path_test)\n",
    "\n",
    "plotImages(pos_images_train[0], neg_images_train[0])\n",
    "\n",
    "# Training set\n",
    "print(len(pos_images_train), len(neg_images_train))\n",
    "# Testing set\n",
    "print(len(pos_images_test), len(neg_images_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) (1 point)** Extract pixel intensity information from the set of images by calculating the histogram with a precision of 20 bins. \n",
    "\n",
    "You should have a resulting matrix for the training set with a size of (90, 20), 200 images and 20 features per image (one channel). And a resulting matrix for the test set with a size of (100, 20), 100 images and 20 features per images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING set\n",
    "# Join all images in a list\n",
    "train_images = neg_images_train + pos_images_train\n",
    "# Obtain class labels\n",
    "train_labels = list(np.zeros(len(neg_images_train))) + list(np.ones(len(pos_images_train)))\n",
    "train_labels = [int(l) for l in train_labels]\n",
    "\n",
    "# TESTING set\n",
    "# Join all images in a list\n",
    "test_images = neg_images_test + pos_images_test\n",
    "# Obtain class labels\n",
    "test_labels = list(np.zeros(len(neg_images_test))) + list(np.ones(len(pos_images_test)))\n",
    "test_labels = [int(l) for l in test_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_from_hist(image, nbins):\n",
    "    # COMPLETE\n",
    "\n",
    "    return features_for_im\n",
    "\n",
    "def getImageFeatures(all_images, nbins):\n",
    "    # COMPLETE\n",
    "\n",
    "    return all_feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "nbins=20\n",
    "train_features = getImageFeatures(train_images, nbins)\n",
    "test_features = getImageFeatures(test_images, nbins)\n",
    "\n",
    "# It takes around 6 min to extract the features of both train and test samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) (1 point)** We will use the class `sklearn.ensemble.AdaBoostClassifier` to implement a classifier for predicting the output of new samples. The class is used to train the classifier, and after that, to generate the probability that a given sample corresponds to a face. If the probability is above a given threshold, then the sample is classified as a face.\n",
    "\n",
    "The implementation is given below, however, you should complete the code of two functions:\n",
    "\n",
    "- `predLabelsFromFaceProbs(isFaceProbs, threshold)`: given a list with the probability of each sample being a face, this function returns a list of labels for the samples. For a given sample, the label will be 1 if the corresponding probability is above the threshold and 0 otherwise.\n",
    "\n",
    "- `predictAdaboost(classifier, features, threshold)`: this function obtains the predicted classes for a list of features given a classifier, a list of features for each sample and a threshold. For this purpose, the probability of face for each sample should be obtained. Once we have the probabilities, they are used to predict the labels according to the given threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "def trainAdaboost(features, true_labels):\n",
    "    classifier = AdaBoostClassifier()\n",
    "    classifier.fit(features, true_labels)\n",
    "    return classifier\n",
    "\n",
    "def getProbsAdaboost(classifier, features):\n",
    "    return classifier.predict_proba(features)\n",
    "\n",
    "def getIsFaceProbs(classifier, features):\n",
    "    probsAdaboost = getProbsAdaboost(classifier, features)\n",
    "    isFaceProbs = []\n",
    "    for p in probsAdaboost:\n",
    "        isFaceProbs.append(p[1])\n",
    "    return isFaceProbs\n",
    "    \n",
    "def predLabelsFromFaceProbs(isFaceProbs, threshold=0.5):\n",
    "    labels = []\n",
    "    # COMPLETE\n",
    "\n",
    "    return labels\n",
    "\n",
    "def predictAdaboost(classifier, features, threshold=0.5):\n",
    "    # COMPLETE\n",
    "\n",
    "adaboost = trainAdaboost(train_features, train_labels)\n",
    "\n",
    "threshold = 0.5\n",
    "predicted_train_labels = predictAdaboost(adaboost, train_features, threshold)\n",
    "predicted_test_labels = predictAdaboost(adaboost, test_features, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) (1.5 points)** Implement a function for calculating the prediction precision given a set of true labels and a set of predicted labels. Precision is obtained as the number of correctly classified faces divided by the total number of images classified as a face (remember, faces have 1 as label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(true_labels, predicted_labels):\n",
    "    # COMPLETE\n",
    "\n",
    "    return prec\n",
    "\n",
    "# Print training precision\n",
    "# COMPLETE\n",
    "\n",
    "# Print testing precision\n",
    "# COMPLETE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
